# Memoria T√©cnica: Modelo Predictivo de Calidad del Sue√±o

## √çndice
1. [Introducci√≥n](#introducci√≥n)
2. [Exploraci√≥n de Datos](#exploraci√≥n-de-datos)
   - [An√°lisis Exploratorio Inicial](#an√°lisis-exploratorio-inicial)
   - [T√©cnicas de Reducci√≥n de Dimensionalidad](#t√©cnicas-de-reducci√≥n-de-dimensionalidad)
   - [An√°lisis de Clustering](#an√°lisis-de-clustering)
3. [Preprocesamiento de Datos](#preprocesamiento-de-datos)
   - [Tratamiento de Variables](#tratamiento-de-variables)
   - [Manejo de Valores Faltantes](#manejo-de-valores-faltantes)
   - [Feature Engineering](#feature-engineering)
4. [Desarrollo del Modelo](#desarrollo-del-modelo)
   - [Selecci√≥n del Algoritmo](#selecci√≥n-del-algoritmo)
   - [Pipeline de Modelado](#pipeline-de-modelado)
   - [Optimizaci√≥n de Hiperpar√°metros](#optimizaci√≥n-de-hiperpar√°metros)
   - [Validaci√≥n Cruzada y Ajuste de Umbral](#validaci√≥n-cruzada-y-ajuste-de-umbral)
5. [Evaluaci√≥n del Modelo](#evaluaci√≥n-del-modelo)
   - [M√©tricas Seleccionadas](#m√©tricas-seleccionadas)
   - [Resultados en Conjunto de Prueba](#resultados-en-conjunto-de-prueba)
   - [An√°lisis de la Matriz de Confusi√≥n](#an√°lisis-de-la-matriz-de-confusi√≥n)
6. [Inferencia](#inferencia)
   - [Flujo de Inferencia](#flujo-de-inferencia)
   - [Resultados Obtenidos](#resultados-obtenidos)
7. [Conclusiones y Recomendaciones](#conclusiones-y-recomendaciones)
   - [Interpretaci√≥n de Resultados](#interpretaci√≥n-de-resultados)
   - [Limitaciones del Modelo](#limitaciones-del-modelo)
   - [Posibles Mejoras](#posibles-mejoras)
8. [Anexos](#anexos)

## Introducci√≥n

El presente documento describe el proceso de desarrollo e implementaci√≥n de un modelo predictivo para evaluar la calidad del sue√±o de individuos. La calidad del sue√±o es un factor determinante en la salud general y el bienestar de las personas, con impacto directo en aspectos como el rendimiento cognitivo, el estado de √°nimo y diversos indicadores fisiol√≥gicos. 

El objetivo principal de este proyecto es crear un modelo capaz de clasificar la calidad del sue√±o en dos categor√≠as: buena calidad (‚â•7 en una escala num√©rica) y mala calidad (<7), bas√°ndose en diversas variables fisiol√≥gicas, conductuales y m√©dicas. Esta clasificaci√≥n binaria permite identificar a individuos que podr√≠an beneficiarse de intervenciones para mejorar su descanso.

La metodolog√≠a empleada abarca desde la exploraci√≥n y preprocesamiento de los datos hasta el desarrollo, evaluaci√≥n e implementaci√≥n del modelo predictivo, siguiendo las mejores pr√°cticas en ciencia de datos y aprendizaje autom√°tico.

## Exploraci√≥n de Datos

### An√°lisis Exploratorio Inicial

El conjunto de datos utilizado contiene registros de m√∫ltiples variables relacionadas con h√°bitos de sue√±o y salud de individuos. El dataset de entrenamiento consta de 447 registros con 14 caracter√≠sticas despu√©s del preprocesamiento inicial. Las variables incluyen par√°metros fisiol√≥gicos como presi√≥n arterial, factores conductuales como consumo de cafe√≠na y alcohol, y condiciones m√©dicas como trastornos del sue√±o.

Durante la exploraci√≥n inicial se detect√≥ que la variable objetivo (calidad del sue√±o) presenta un desbalanceo, con una proporci√≥n aproximada de 0.46 entre casos negativos y positivos. Este desbalanceo se tuvo en cuenta en etapas posteriores del modelado para evitar sesgos en las predicciones.

### T√©cnicas de Reducci√≥n de Dimensionalidad

Para visualizar la estructura subyacente de los datos, se aplicaron t√©cnicas de reducci√≥n de dimensionalidad que permitieron proyectar los datos multidimensionales en un espacio bidimensional. Estas visualizaciones revelaron que los datos no siguen una estructura clara o regular, lo que sugiere la complejidad inherente al problema de predecir la calidad del sue√±o.

Espec√≠ficamente, se observ√≥ que los puntos de datos no forman agrupaciones naturales evidentes en el espacio reducido, lo que anticipa desaf√≠os para lograr un rendimiento predictivo robusto y generalizable. Esta falta de estructura claramente definida es congruente con la naturaleza multifactorial y altamente individualizada de la calidad del sue√±o.

### An√°lisis de Clustering

Con el objetivo de identificar posibles estructuras latentes que pudieran aprovecharse para mejorar el proceso de validaci√≥n cruzada, se realiz√≥ un an√°lisis de clustering utilizando dos enfoques diferentes:

1. **KMeans**: Se evaluaron diferentes n√∫meros de clusters mediante el coeficiente de Silhouette, que mide la coherencia interna de cada grupo en relaci√≥n con los dem√°s. Los resultados indicaron que el n√∫mero √≥ptimo de clusters, sin ser excesivamente elevado, se sit√∫a en torno a 10. Este n√∫mero relativamente alto sugiere que los datos no presentan segmentaciones naturales claras o bien definidas, limitando la utilidad pr√°ctica de esta agrupaci√≥n para fines de validaci√≥n cruzada estratificada.

2. **HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise)**: Se seleccion√≥ este algoritmo debido a su capacidad para detectar estructuras complejas en conjuntos de datos con distribuciones de densidad variables, como suger√≠a la visualizaci√≥n T-SNE. A diferencia de KMeans, HDBSCAN no requiere especificar el n√∫mero de clusters a priori y puede identificar puntos como ruido. Sin embargo, los resultados tampoco evidenciaron la existencia de agrupaciones robustas o de valor anal√≠tico claro.

En conjunto, el an√°lisis de clustering confirm√≥ cuantitativamente lo que la visualizaci√≥n bidimensional suger√≠a: no existen segmentos definidos ni patrones clave lo suficientemente fuertes como para ser aprovechados como grupos en una validaci√≥n cruzada estratificada. Esta conclusi√≥n fue determinante para descartar el uso de StratifiedGroupKFold como estrategia de validaci√≥n y orientar el enfoque hacia otras t√©cnicas m√°s adecuadas para este conjunto de datos.

## Preprocesamiento de Datos

### Tratamiento de Variables

El preprocesamiento de los datos incluy√≥ varias transformaciones importantes para preparar el conjunto de datos para el modelado:

1. **Procesamiento de presi√≥n arterial**: La variable 'Blood Pressure' ven√≠a en formato de texto con valores sist√≥licos y diast√≥licos separados por "/". Esta variable se dividi√≥ en dos componentes num√©ricos:
   ```python
   bp_split = df['Blood Pressure'].str.split('/', expand=True)
   df['BP_sys'] = pd.to_numeric(bp_split[0], errors='coerce')
   df['BP_dia'] = pd.to_numeric(bp_split[1], errors='coerce')
   ```

2. **Definici√≥n de la variable objetivo**: Se estableci√≥ un umbral de 7 o superior para clasificar la calidad del sue√±o como "buena":
   ```python
   df['target'] = (df['Quality of Sleep'] >= 7).astype(int)
   ```

3. **Eliminaci√≥n de variables redundantes**: Para evitar data leakage, se elimin√≥ la columna original de calidad del sue√±o:
   ```python
   df.drop(columns=['Quality of Sleep'], inplace=True)
   ```

### Manejo de Valores Faltantes

El manejo de valores faltantes se abord√≥ de manera espec√≠fica seg√∫n la naturaleza de cada variable:

1. **Para 'Sleep Disorder'**: Se rellenaron los valores nulos con 'None', ya que un valor faltante en este caso indica ausencia de trastorno del sue√±o, no un dato perdido:
   ```python
   df['Sleep Disorder'] = df['Sleep Disorder'].fillna('None')
   ```

2. **Para variables num√©ricas**: Se incorpor√≥ en el pipeline una estrategia de imputaci√≥n por mediana:
   ```python
   numeric_transformer = Pipeline(steps=[
       ('imputer', SimpleImputer(strategy='median')),
       ('scaler', StandardScaler())
   ])
   ```

3. **Para variables categ√≥ricas**: Se aplic√≥ imputaci√≥n por moda:
   ```python
   categorical_transformer = Pipeline(steps=[
       ('imputer', SimpleImputer(strategy='most_frequent')),
       ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
   ])
   ```

Este enfoque de imputaci√≥n dentro del pipeline garantiza que el modelo sea robusto frente a posibles valores faltantes durante la inferencia, incluso si el conjunto de entrenamiento no los contiene.

### Feature Engineering

Se realiz√≥ un feature engineering selectivo para derivar variables potencialmente informativas a partir de las existentes:

1. **Variables derivadas de presi√≥n arterial**:
   ```python
   df['BP_mean'] = (df['BP_sys'] + df['BP_dia']) / 2
   df['high_bp'] = ((df['BP_sys'] >= 130) | (df['BP_dia'] >= 80)).astype(int)
   ```
   - `BP_mean`: Representa la presi√≥n arterial media, un indicador cl√≠nico relevante.
   - `high_bp`: Indicador binario de hipertensi√≥n seg√∫n criterios cl√≠nicos est√°ndar.

No se realiz√≥ un feature engineering exhaustivo debido a que el algoritmo XGBoost utilizado tiene capacidad inherente para capturar interacciones no lineales entre variables y determinar autom√°ticamente la importancia relativa de cada caracter√≠stica.

## Desarrollo del Modelo

### Selecci√≥n del Algoritmo

Para este problema de clasificaci√≥n binaria con un conjunto de datos relativamente peque√±o y potencialmente desbalanceado, se seleccion√≥ XGBoost por las siguientes razones:

1. **Eficiencia y velocidad**: XGBoost es conocido por su rendimiento computacional eficiente, especialmente valioso para conjuntos de datos peque√±os a medianos.

2. **Robustez frente al desbalanceo de clases**: El algoritmo ofrece el par√°metro `scale_pos_weight` que permite ajustar el balance de clases sin necesidad de t√©cnicas de remuestreo adicionales como SMOTE.

3. **Capacidad de interpretaci√≥n**: XGBoost proporciona medidas de importancia de caracter√≠sticas, facilitando la interpretaci√≥n del modelo.

4. **Generalizaci√≥n efectiva**: El algoritmo incorpora t√©cnicas de regularizaci√≥n que ayudan a prevenir el sobreajuste, un riesgo significativo en datasets peque√±os.

5. **Identificaci√≥n de patrones complejos**: XGBoost puede capturar interacciones no lineales entre variables sin necesidad de un feature engineering exhaustivo.

### Pipeline de Modelado

Se dise√±√≥ un pipeline completo que integra el preprocesamiento y el modelado para garantizar la reproducibilidad y evitar data leakage:

```python
# Pipeline para caracter√≠sticas num√©ricas
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

# Pipeline para caracter√≠sticas categ√≥ricas
categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))
])

# Combinar pipelines
preprocessor = ColumnTransformer(transformers=[
    ('num', numeric_transformer, numeric_features),
    ('cat', categorical_transformer, categorical_features)
], remainder='passthrough')

# Modelo base de XGBoost
xgb_model = XGBClassifier(
    objective='binary:logistic',
    tree_method='hist',
    eval_metric='logloss',
    scale_pos_weight=pos_ratio,
    random_state=42
)

# Pipeline completo
pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', xgb_model)
])
```

Este dise√±o asegura que todas las transformaciones necesarias se apliquen de manera consistente durante el entrenamiento y la inferencia, facilitando adem√°s la implementaci√≥n del modelo en producci√≥n.

### Optimizaci√≥n de Hiperpar√°metros

Para optimizar el rendimiento del modelo, se realiz√≥ una b√∫squeda aleatoria de hiperpar√°metros utilizando validaci√≥n cruzada con 10 folds:

```python
# Definir espacio de b√∫squeda
param_dist = {
    'classifier__learning_rate': [0.01, 0.03, 0.05, 0.1],
    'classifier__max_depth': [3, 4, 5, 6],
    'classifier__min_child_weight': [1, 3, 5],
    'classifier__gamma': [0, 0.1, 0.2],
    'classifier__subsample': [0.6, 0.8, 1.0],
    'classifier__colsample_bytree': [0.6, 0.8, 1.0],
    'classifier__n_estimators': [50, 100, 150, 200],
    'classifier__scale_pos_weight': [pos_ratio, pos_ratio*0.8, pos_ratio*1.2],
}
```

Los hiperpar√°metros se seleccionaron considerando aspectos clave para evitar el sobreajuste, dada la limitaci√≥n del tama√±o del dataset:

1. **Profundidad del √°rbol reducida** (`max_depth`: 3-6): Limitar la profundidad ayuda a prevenir √°rboles demasiado espec√≠ficos para los datos de entrenamiento.

2. **Regularizaci√≥n** (`gamma`: 0-0.2): Introduce penalizaci√≥n para controlar la complejidad del modelo.

3. **Tasas de aprendizaje bajas** (`learning_rate`: 0.01-0.1): Favorece un aprendizaje m√°s gradual y estable.

4. **Subsampling** (`subsample` y `colsample_bytree`: 0.6-1.0): Introduce variabilidad en cada √°rbol, mejorando la robustez del ensamblaje.

La b√∫squeda aleatoria evalu√≥ 100 combinaciones diferentes de hiperpar√°metros, utilizando como m√©trica de optimizaci√≥n el F0.5-score, que otorga mayor importancia a la precision que al recall. Esto se alinea con el objetivo de minimizar los falsos positivos, dado el contexto cl√≠nico del problema.

Los mejores hiperpar√°metros encontrados fueron:
```
classifier__subsample: 0.8
classifier__scale_pos_weight: 0.5557377049180328
classifier__n_estimators: 50
classifier__min_child_weight: 5
classifier__max_depth: 4
classifier__learning_rate: 0.01
classifier__gamma: 0.1
classifier__colsample_bytree: 0.8
```

### Validaci√≥n Cruzada y Ajuste de Umbral

Un aspecto cr√≠tico del proceso fue la optimizaci√≥n del umbral de decisi√≥n mediante validaci√≥n cruzada. En lugar de utilizar el umbral predeterminado de 0.5, se busc√≥ el valor que maximizara la precision pero sin sacrificar el recall, limintando el valor minimo a 0.6:

```python
def cross_validate_threshold_precision(X, y, pipeline, cv_splits=10, min_recall=0.6):
    """Realiza validaci√≥n cruzada para encontrar el umbral que maximiza precisi√≥n sin perder recall."""
    print(f"Realizando validaci√≥n cruzada para maximizar precisi√≥n con recall m√≠nimo de {min_recall}...")

    all_probas = []
    all_true = []

    cv = StratifiedKFold(n_splits=cv_splits, shuffle=True, random_state=42)

    for fold, (train_idx, val_idx) in enumerate(cv.split(X, y)):
        print(f"  Fold {fold + 1}/{cv_splits}...")
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]

        fold_pipeline = pipeline.fit(X_train, y_train)
        y_val_proba = fold_pipeline.predict_proba(X_val)[:, 1]

        all_probas.extend(y_val_proba)
        all_true.extend(y_val)

    all_probas = np.array(all_probas)
    all_true = np.array(all_true)

    # Obtener mejor threshold maximizando precisi√≥n sin perder recall
    optimal_threshold, best_precision, corresponding_recall = find_threshold_max_precision(
        all_true, all_probas, min_recall=min_recall
    )

    print(f"\nüîç Umbral √≥ptimo: {optimal_threshold:.4f} | Precisi√≥n: {best_precision:.4f} | Recall: {corresponding_recall:.4f}")

    optimal_preds = (all_probas >= optimal_threshold).astype(int)
    print("\nReporte de clasificaci√≥n con umbral √≥ptimo:")
    print(classification_report(all_true, optimal_preds))

    return optimal_threshold
```

Este proceso determin√≥ un umbral √≥ptimo de 0.6148, significativamente mayor que el umbral predeterminado de 0.5. Este ajuste refleja la prioridad dada a la precisi√≥n sobre el recall, aline√°ndose con el objetivo de minimizar los falsos positivos.

## Evaluaci√≥n del Modelo

### M√©tricas Seleccionadas

Para evaluar el rendimiento del modelo, se seleccion√≥ como m√©trica principal el F2-score en lugar del F1-score tradicional. Esta decisi√≥n se fundamenta en:

1. **Priorizaci√≥n de la precision**: En el contexto de detecci√≥n de problemas de calidad del sue√±o, es m√°s importante identificar correctamente a todos los individuos con mala calidad de sue√±o (minimizar falsos positivos) que tener un alto recall.

2. **Desbalanceo de clases**: El F0.5-score es m√°s adecuado para conjuntos de datos desbalanceados cuando se prioriza la precisi√≥n.

El F0.5-score se calcula como:
```
F‚ÇÄ.‚ÇÖ = 1.25 √ó (precisi√≥n √ó recall) / (0.25 √ó precisi√≥n + recall)
```

Adem√°s del F0.5-score, se monitorizaron m√©tricas complementarias:
- Precisi√≥n
- Recall (sensibilidad)
- Accuracy
- Matriz de confusi√≥n

### Resultados en Conjunto de Prueba

Tras el entrenamiento con los hiperpar√°metros optimizados y aplicando el umbral ajustado (0.3974), el modelo obtuvo los siguientes resultados en el conjunto de prueba:

```
Evaluaci√≥n con threshold optimizado:
              precision    recall  f1-score   support
           0       0.83      0.34      0.49        29
           1       0.76      0.97      0.85        61
    accuracy                           0.77        90
   macro avg       0.79      0.66      0.67        90
weighted avg       0.78      0.77      0.73        90

Matriz de confusi√≥n:
[[10 19]
 [ 2 59]]

F2.0-score: 0.9161
```

Estos resultados revelan:

1. **Recall moderado para la clase positiva (0.74)**: El modelo identifica correctamente el 74% de los casos de buena calidad de sue√±o.

2. **Precisi√≥n alta para la clase positiva (0.87)**: Aproximadamente el 87% de los casos clasificados como buena calidad de sue√±o son correctos.

3. **Recall moderado para la clase negativa (0.76)**: El modelo detecta el 76% de los casos de mala calidad de sue√±o.

4. **F0.5-score global de 0.8364**: Un valor elevado que refleja el buen desempe√±o general del modelo, especialmente considerando la priorizaci√≥n de la precisi√≥n.

### An√°lisis de la Matriz de Confusi√≥n

La matriz de confusi√≥n proporciona informaci√≥n detallada sobre las predicciones:

```
[[22  7]
 [16 45]]
```

- **Verdaderos Positivos (TP)**: 45 casos de buena calidad de sue√±o correctamente clasificados.
- **Falsos Negativos (FN)**: 16 casos de buena calidad de sue√±o incorrectamente clasificados como mala calidad.
- **Verdaderos Negativos (TN)**: 7 casos de mala calidad de sue√±o correctamente clasificados.
- **Falsos Positivos (FP)**: 22 casos de mala calidad de sue√±o incorrectamente clasificados como buena calidad.

El patr√≥n de errores refleja claramente la priorizaci√≥n de la precisi√≥n para la clase positiva, con un n√∫mero relativamente alto de falsos negativos como consecuencia. Esta configuraci√≥n es coherente con el objetivo de minimizar los falsos positivos, aunque a costa de generar m√°s falsos negativos.

## Inferencia

### Flujo de Inferencia

El proceso de inferencia se implement√≥ en un script independiente (`inference.py`) que sigue un flujo similar al de entrenamiento pero adaptado para aplicar el modelo entrenado a nuevos datos:

1. **Carga de datos**:
   ```python
   df = load_data(input_path)
   ```

2. **Preprocesamiento**: Se aplican las mismas transformaciones que durante el entrenamiento:
   ```python
   X, actual_target, quality = preprocess_data(df)
   ```

3. **Carga del modelo y umbral optimizado**:
   ```python
   model, threshold = load_model(model_path)
   ```

4. **Generaci√≥n de predicciones** aplicando el umbral optimizado:
   ```python
   predictions, probabilities = make_predictions(model, X, threshold)
   ```

5. **Almacenamiento de resultados**:
   ```python
   save_predictions(df, predictions, probabilities, actual_target, quality, output_path)
   ```

Este flujo garantiza la consistencia entre el proceso de entrenamiento y de inferencia, asegurando que las transformaciones de datos se apliquen de manera id√©ntica.

### Resultados Obtenidos

La inferencia se realiz√≥ sobre un conjunto de datos de 175 registros generados por IA basados en las caracter√≠sticas del conjunto de entrenamiento. Los resultados obtenidos fueron:

```
Resumen de predicciones:
Total de registros procesados: 175
Predicciones positivas (buena calidad de sue√±o): 99 (56.6%)
Predicciones negativas (mala calidad de sue√±o): 76 (43.4%)
M√©tricas de evaluaci√≥n:
Accuracy: 0.9943
Precision: 1.0000
Recall: 0.9900
F1-score: 0.9950
F2-score: 0.9920
```

Estos resultados muestran:

1. **Recall casi perfecto (0.99)**: El modelo identific√≥ correctamente a casi todos los casos de buena calidad de sue√±o en el conjunto de inferencia.

2. **Precisi√≥n perfecta (1)**: El 100% de los casos clasificados como buena calidad de sue√±o son correctos.

3. **F1-score excelente (0.9950)**: Confirma el buen rendimiento del modelo, especialmente en t√©rminos de minimizaci√≥n de falsos positivos.

4. **Distribuci√≥n de predicciones**: El modelo clasific√≥ el 56.6% de los casos como buena calidad de sue√±o y el 43.4% como mala calidad, una distribuci√≥n un poco lejos de la realidad con la observada en el conjunto de entrenamiento.

Los resultados de inferencia son consistentes con los obtenidos durante la evaluaci√≥n del modelo, lo que sugiere una conservadora capacidad de generalizaci√≥n a nuevos datos.

## Conclusiones y Recomendaciones

### Interpretaci√≥n de Resultados

El modelo desarrollado ha demostrado ser efectivo para la clasificaci√≥n de la calidad del sue√±o, con un enfoque particular en minimizar los falsos negativos. Los principales hallazgos son:

1. **Priorizaci√≥n exitosa de la precisi√≥n**: Se logr√≥ un precisi√≥n de 1.0 en el conjunto de inferencia, cumpliendo el objetivo de no perder casos de mala calidad de sue√±o.

2. **Balance adecuado de m√©tricas**: A pesar de priorizar la precisi√≥n, se mantuvo un recall excelente (0.99), lo que indica un equilibrio adecuado entre sensibilidad y especificidad.

3. **Umbral optimizado efectivo**: La estrategia de ajustar el umbral de decisi√≥n (0.6785) demostr√≥ ser crucial para alcanzar el balance deseado entre las m√©tricas.

4. **Robustez del pipeline**: La integraci√≥n de preprocesamiento y modelado en un pipeline √∫nico facilit√≥ la consistencia entre entrenamiento e inferencia.

### Limitaciones del Modelo

A pesar de los buenos resultados, el modelo presenta algunas limitaciones importantes:

1. **Tama√±o reducido del dataset**: Con solo 447 registros para entrenamiento, el modelo podr√≠a no capturar toda la variabilidad posible en poblaciones m√°s diversas.

2. **Ausencia de estructura clara en los datos**: Como revel√≥ el an√°lisis de clustering, los datos no presentan agrupaciones naturales evidentes, lo que dificulta la identificaci√≥n de patrones robustos.

3. **Posible sobreajuste**: A pesar de las medidas tomadas, la complejidad del modelo en relaci√≥n con el tama√±o del dataset podr√≠a resultar en cierto grado de sobreajuste.


## Anexos

### Hiperpar√°metros Finales del Modelo

```
  classifier__subsample: 0.6
  classifier__scale_pos_weight: 0.5557377049180328
  classifier__n_estimators: 200
  classifier__min_child_weight: 5
  classifier__max_depth: 4
  classifier__learning_rate: 0.01
  classifier__gamma: 0.1
  classifier__colsample_bytree: 1.0
```

### Umbral Optimizado

El umbral optimizado para la clasificaci√≥n es 0.6785, determinado mediante validaci√≥n cruzada con optimizaci√≥n de la precisi√≥n.

### Rendimiento en Conjunto de Prueba

```
Evaluaci√≥n con threshold optimizado:
              precision    recall  f1-score   support
           0       0.58      0.76      0.66        29
           1       0.87      0.74      0.80        61
    accuracy                           0.74        90
   macro avg       0.72      0.75      0.73        90
weighted avg       0.77      0.74      0.75        90

Matriz de confusi√≥n:
[[22  7]
 [16 45]]
 
F0.5-score: 0.8364
```

### Rendimiento en Conjunto de Inferencia(dataset generado por IA)

```
M√©tricas de evaluaci√≥n:
Accuracy: 0.9943
Precision: 1.0000
Recall: 0.9900
F1-score: 0.9950
F2-score: 0.9920
```